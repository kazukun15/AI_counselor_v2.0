import streamlit as st
import requests
import re
from streamlit_chat import message  # pip install streamlit-chat

# ------------------------
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
# ------------------------
st.set_page_config(page_title="ãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢ãƒœãƒƒãƒˆ", layout="wide")

# ------------------------
# ã‚«ã‚¹ã‚¿ãƒ CSSã®æŒ¿å…¥ï¼ˆæŸ”ã‚‰ã‹ã„è–„ã„ãƒ”ãƒ³ã‚¯ãƒ»é»„è‰²ï¼‰
# ------------------------
st.markdown(
    """
    <style>
    /* ãƒ¡ã‚¤ãƒ³ç”»é¢ã®èƒŒæ™¯ã‚’è–„ã„ãƒ”ãƒ³ã‚¯ã«è¨­å®š */
    .reportview-container {
        background: #FFF0F5;
    }
    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯ã‚’æŸ”ã‚‰ã‹ã„é»„è‰²ã«è¨­å®š */
    .sidebar .sidebar-content {
        background: #FFF5EE;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ------------------------
# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤ºï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›ã®ä¸Šéƒ¨ã«è¡¨ç¤ºï¼‰
# ------------------------
st.title("ãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢ãƒœãƒƒãƒˆ")

# ------------------------
# ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›ï¼ˆç”»é¢ä¸Šéƒ¨ï¼‰
# ------------------------
user_name = st.text_input("ã‚ãªãŸã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value="æ„›åª›çœŒåºè·å“¡", key="user_name")
col1, col2 = st.columns([3, 1])
with col1:
    consult_type = st.radio("ç›¸è«‡ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„", 
                            ("æœ¬äººã®ç›¸è«‡", "ä»–è€…ã®ç›¸è«‡", "ãƒ‡ãƒªã‚±ãƒ¼ãƒˆãªç›¸è«‡"), key="consult_type")
with col2:
    if st.button("é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ã‚’é–‹ã", key="open_form"):
        st.session_state["show_selection_form"] = True

# ------------------------
# å®šæ•°ï¼è¨­å®š
# ------------------------
API_KEY = st.secrets["general"]["api_key"]
MODEL_NAME = "gemini-2.0-flash-001"  # å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´
ROLES = ["ç²¾ç¥ç§‘åŒ»å¸«", "ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼", "ãƒ¡ãƒ³ã‚¿ãƒªã‚¹ãƒˆ", "å†…ç§‘åŒ»"]

# ------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–ï¼ˆä¼šè©±ã‚¿ãƒ¼ãƒ³å˜ä½ã§ç®¡ç†ï¼‰
# ------------------------
if "conversation_turns" not in st.session_state:
    st.session_state["conversation_turns"] = []
if "show_selection_form" not in st.session_state:
    st.session_state["show_selection_form"] = False

# ------------------------
# é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# ------------------------
if st.session_state.get("show_selection_form", False):
    st.sidebar.header("é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ")
    category = st.sidebar.selectbox("æ‚©ã¿ã®ç¨®é¡", ["äººé–“é–¢ä¿‚", "ä»•äº‹", "å®¶åº­", "çµŒæ¸ˆ", "å¥åº·", "ãã®ä»–"], key="category")
    
    st.sidebar.subheader("èº«ä½“ã®çŠ¶æ…‹")
    physical_status = st.sidebar.radio("èº«ä½“ã®çŠ¶æ…‹", ["è‰¯å¥½", "æ™®é€š", "ä¸èª¿"], key="physical")
    physical_detail = st.sidebar.text_area("èº«ä½“ã®çŠ¶æ…‹ã®è©³ç´°", key="physical_detail", placeholder="å…·ä½“çš„ãªç—‡çŠ¶ã‚„å¤‰åŒ–ã‚’è¨˜å…¥")
    physical_duration = st.sidebar.selectbox("èº«ä½“ã®ç—‡çŠ¶ã®æŒç¶šæœŸé–“", ["æ•°æ—¥", "1é€±é–“", "1ãƒ¶æœˆä»¥ä¸Š", "ä¸æ˜"], key="physical_duration")
    
    st.sidebar.subheader("å¿ƒã®çŠ¶æ…‹")
    mental_status = st.sidebar.radio("å¿ƒã®çŠ¶æ…‹", ["è½ã¡ç€ã„ã¦ã„ã‚‹", "ã‚„ã‚„ä¸å®‰", "ã¨ã¦ã‚‚ä¸å®‰"], key="mental")
    mental_detail = st.sidebar.text_area("å¿ƒã®çŠ¶æ…‹ã®è©³ç´°", key="mental_detail", placeholder="æ„Ÿã˜ã¦ã„ã‚‹ä¸å®‰ã‚„ã‚¹ãƒˆãƒ¬ã‚¹ã®å†…å®¹ã‚’è¨˜å…¥")
    mental_duration = st.sidebar.selectbox("å¿ƒã®ç—‡çŠ¶ã®æŒç¶šæœŸé–“", ["æ•°æ—¥", "1é€±é–“", "1ãƒ¶æœˆä»¥ä¸Š", "ä¸æ˜"], key="mental_duration")
    
    stress_level = st.sidebar.slider("ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ« (1-10)", 1, 10, 5, key="stress")
    recent_events = st.sidebar.text_area("æœ€è¿‘ã®å¤§ããªå‡ºæ¥äº‹ï¼ˆä»»æ„ï¼‰", key="events")
    treatment_history = st.sidebar.radio("é€šé™¢æ­´ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ", ["ã¯ã„", "ã„ã„ãˆ"], key="treatment")
    ongoing_treatment = ""
    if treatment_history == "ã¯ã„":
        ongoing_treatment = st.sidebar.radio("ç¾åœ¨ã‚‚é€šé™¢ä¸­ã§ã™ã‹ï¼Ÿ", ["ã¯ã„", "ã„ã„ãˆ"], key="ongoing")
    
    if st.sidebar.button("é¸æŠå†…å®¹ã‚’é€ä¿¡", key="submit_selection"):
        selection_summary = (
            f"ã€é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ã€‘\n"
            f"æ‚©ã¿ã®ç¨®é¡: {category}\n"
            f"èº«ä½“ã®çŠ¶æ…‹: {physical_status}\n"
            f"èº«ä½“ã®è©³ç´°: {physical_detail}\n"
            f"èº«ä½“ã®ç—‡çŠ¶ã®æŒç¶šæœŸé–“: {physical_duration}\n"
            f"å¿ƒã®çŠ¶æ…‹: {mental_status}\n"
            f"å¿ƒã®è©³ç´°: {mental_detail}\n"
            f"å¿ƒã®ç—‡çŠ¶ã®æŒç¶šæœŸé–“: {mental_duration}\n"
            f"ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«: {stress_level}\n"
            f"æœ€è¿‘ã®å‡ºæ¥äº‹: {recent_events}\n"
            f"é€šé™¢æ­´: {treatment_history}\n"
        )
        if treatment_history == "ã¯ã„":
            selection_summary += f"ç¾åœ¨ã®é€šé™¢çŠ¶æ³: {ongoing_treatment}\n"
        if "conversation_turns" not in st.session_state or not isinstance(st.session_state["conversation_turns"], list):
            st.session_state["conversation_turns"] = []
        st.session_state["conversation_turns"].append({
            "user": selection_summary, 
            "answer": "é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ã®å†…å®¹ãŒé€ä¿¡ã•ã‚Œã€åæ˜ ã•ã‚Œã¾ã—ãŸã€‚"
        })
        st.sidebar.success("é€ä¿¡ã—ã¾ã—ãŸï¼")

# ------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆãƒãƒ£ãƒƒãƒˆç”Ÿæˆãƒ»è¡¨ç¤ºï¼‰
# ------------------------
def truncate_text(text, max_length=400):
    return text if len(text) <= max_length else text[:max_length] + "â€¦"

def split_message(message: str, chunk_size=200) -> list:
    chunks = []
    while len(message) > chunk_size:
        break_point = -1
        for punct in ["ã€‚", "ï¼", "ï¼Ÿ"]:
            pos = message.rfind(punct, 0, chunk_size)
            if pos > break_point:
                break_point = pos
        if break_point == -1:
            break_point = chunk_size
        else:
            break_point += 1
        chunks.append(message[:break_point].strip())
        message = message[break_point:].strip()
    if message:
        chunks.append(message)
    return chunks

def remove_json_artifacts(text: str) -> str:
    if not isinstance(text, str):
        text = str(text) if text else ""
    pattern = r"'parts': \[\{'text':.*?\}\], 'role': 'model'"
    cleaned = re.sub(pattern, "", text, flags=re.DOTALL)
    return cleaned.strip()

def call_gemini_api(prompt: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={API_KEY}"
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(url, json=payload, headers=headers)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡æ™‚ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ -> {str(e)}"
    if response.status_code != 200:
        return f"ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status_code} -> {response.text}"
    try:
        rjson = response.json()
        candidates = rjson.get("candidates", [])
        if not candidates:
            return "å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        candidate0 = candidates[0]
        content_val = candidate0.get("content", "")
        if isinstance(content_val, dict):
            parts = content_val.get("parts", [])
            content_str = " ".join([p.get("text", "") for p in parts])
        else:
            content_str = str(content_val)
        content_str = content_str.strip()
        if not content_str:
            return "å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        return remove_json_artifacts(content_str)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã«å¤±æ•—ã—ã¾ã—ãŸ -> {str(e)}"

def adjust_parameters(question: str) -> dict:
    params = {}
    params["ç²¾ç¥ç§‘åŒ»å¸«"] = {"style": "å°‚é–€çš„", "detail": "ç²¾ç¥ç§‘ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’åŸºã«çš„ç¢ºãªåˆ¤æ–­ã‚’ä¸‹ã™"}
    params["ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼"] = {"style": "å…±æ„Ÿçš„", "detail": "å¯„ã‚Šæ·»ã„ãªãŒã‚‰å„ªã—ãã‚µãƒãƒ¼ãƒˆã™ã‚‹"}
    params["ãƒ¡ãƒ³ã‚¿ãƒªã‚¹ãƒˆ"] = {"style": "æ´å¯ŸåŠ›ã«å¯Œã‚“ã ", "detail": "å¤šè§’çš„ãªå¿ƒç†å­¦çš„è¦–ç‚¹ã‹ã‚‰åˆ†æã™ã‚‹"}
    params["å†…ç§‘åŒ»"] = {"style": "å®Ÿç›´ãª", "detail": "èº«ä½“é¢ã®ä¸èª¿ã‚„ä»–ã®ç—…æ°—ã‚’æ…é‡ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹"}
    return params

def generate_combined_answer(question: str, persona_params: dict) -> str:
    current_user = st.session_state.get("user_name", "ãƒ¦ãƒ¼ã‚¶ãƒ¼")
    consult_type = st.session_state.get("consult_type", "æœ¬äººã®ç›¸è«‡")
    if consult_type == "ãƒ‡ãƒªã‚±ãƒ¼ãƒˆãªç›¸è«‡":
        consult_info = ("ã“ã®ç›¸è«‡ã¯å¤§äººã®ç™ºé”éšœå®³ï¼ˆä¾‹ï¼šADHDãªã©ï¼‰ã‚’å«ã‚€ã€ãƒ‡ãƒªã‚±ãƒ¼ãƒˆãªç›¸è«‡ã§ã™ã€‚"
                        "ä¿¡é ¼ã§ãã‚‹å…¬çš„æ©Ÿé–¢ã‚„å­¦è¡“è«–æ–‡ã‚’å‚ç…§ã—ã€æ­£ç¢ºãªæƒ…å ±ã«åŸºã¥ã„ãŸå›ç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
    elif consult_type == "ä»–è€…ã®ç›¸è«‡":
        consult_info = "ã“ã®ç›¸è«‡ã¯ã€ä»–è€…ãŒæŠ±ãˆã‚‹éšœå®³ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚å°‚é–€çš„ãªè¦–ç‚¹ã‹ã‚‰å®¢è¦³çš„ãªåˆ¤æ–­ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
    else:
        consult_info = "ã“ã®ç›¸è«‡ã¯æœ¬äººãŒæŠ±ãˆã‚‹æ‚©ã¿ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚"
        
    prompt = f"ã€{current_user}ã•ã‚“ã®è³ªå•ã€‘\n{question}\n\n{consult_info}\n"
    prompt += (
        "ä»¥ä¸‹ã¯ã€4äººã®å°‚é–€å®¶ã®æ„è¦‹ã‚’å†…éƒ¨ã§çµ±åˆã—ãŸçµæœã§ã™ã€‚"
        "å†…éƒ¨ã®è­°è«–å†…å®¹ã¯ä¼ã›ã€ã‚ãªãŸã«å¯¾ã™ã‚‹ä¸€å¯¾ä¸€ã®è‡ªç„¶ãªä¼šè©±ã¨ã—ã¦ã€"
        "ãŸã¨ãˆã°ã€Œã©ã†ã—ãŸã®ï¼Ÿã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã€ã¨ã„ã£ãŸè¿”ç­”ã‚’å«ã‚€å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        "å›ç­”ã¯300ï½400æ–‡å­—ç¨‹åº¦ã§ã€è‡ªç„¶ãªæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    return truncate_text(call_gemini_api(prompt), 400)

def continue_combined_answer(additional_input: str, current_turns: str) -> str:
    prompt = (
        "ã“ã‚Œã¾ã§ã®ä¼šè©±ã®æµã‚Œ:\n" + current_turns + "\n\n" +
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¿½åŠ ç™ºè¨€: " + additional_input + "\n\n" +
        "ä¸Šè¨˜ã®æµã‚Œã‚’è¸ã¾ãˆã€ã•ã‚‰ã«è‡ªç„¶ãªä¼šè©±ã¨ã—ã¦ã€"
        "å°‚é–€å®¶ã¨ã—ã¦ã®è¦‹è§£ã‚’è¸ã¾ãˆãŸå›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        "å›ç­”ã¯300ï½400æ–‡å­—ç¨‹åº¦ã§ã€è‡ªç„¶ãªæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    return truncate_text(call_gemini_api(prompt), 400)

def generate_summary(discussion: str) -> str:
    prompt = (
        "ä»¥ä¸‹ã¯4äººã®çµ±åˆã•ã‚ŒãŸä¼šè©±å†…å®¹ã§ã™:\n" + discussion + "\n\n" +
        "ã“ã®å†…å®¹ã‚’è¸ã¾ãˆã¦ã€æ„›åª›çœŒåºè·å“¡å‘ã‘ã®ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã«é–¢ã™ã‚‹ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ã€"
        "åˆ†ã‹ã‚Šã‚„ã™ã„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    )
    return call_gemini_api(prompt)

def display_chat_bubble(sender: str, message: str, align: str):
    if align == "right":
        bubble_html = f"""
        <div style="
            background-color: #DCF8C6;
            border: 1px solid #ddd;
            border-radius: 10px;
            padding: 8px;
            margin: 5px 0;
            color: #000;
            font-family: Arial, sans-serif;
            text-align: right;
            width: 50%;
            float: right;
            clear: both;
        ">
            <strong>{sender}</strong>: {message} ğŸ˜Š
        </div>
        """
    else:
        bubble_html = f"""
        <div style="
            background-color: #FFFACD;
            border: 1px solid #ddd;
            border-radius: 10px;
            padding: 8px;
            margin: 5px 0;
            color: #000;
            font-family: Arial, sans-serif;
            text-align: left;
            width: 50%;
            float: left;
            clear: both;
        ">
            <strong>{sender}</strong>: {message} ğŸ‘
        </div>
        """
    st.markdown(bubble_html, unsafe_allow_html=True)

def display_conversation_turns(turns: list):
    for turn in reversed(turns):
        display_chat_bubble("ã‚ãªãŸ", turn["user"], "right")
        answer_chunks = split_message(turn["answer"], 200)
        for i, chunk in enumerate(answer_chunks):
            suffix = " ğŸ‘‰" if i < len(answer_chunks) - 1 else ""
            display_chat_bubble("å›ç­”", chunk + suffix, "left")

# ------------------------
# Streamlit ã‚¢ãƒ—ãƒªæœ¬ä½“
# ------------------------
st.title("ãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢ãƒœãƒƒãƒˆ")
st.header("ä¼šè©±å±¥æ­´")
conversation_container = st.empty()

if st.button("æ”¹å–„ç­–ã®ãƒ¬ãƒãƒ¼ãƒˆ"):
    if st.session_state.get("conversation_turns", []):
        all_turns = "\n".join([f"ã‚ãªãŸ: {turn['user']}\nå›ç­”: {turn['answer']}" for turn in st.session_state["conversation_turns"]])
        summary = generate_summary(all_turns)
        st.session_state["summary"] = summary
        st.markdown("### æ”¹å–„ç­–ã®ãƒ¬ãƒãƒ¼ãƒˆ\n" + "**ã¾ã¨ã‚:**\n" + summary)
    else:
        st.warning("ã¾ãšã¯ä¼šè©±ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

st.header("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›")
with st.form("chat_form", clear_on_submit=True):
    user_message = st.text_area("æ–°ãŸãªç™ºè¨€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ã“ã“ã«å…¥åŠ›", height=100, key="user_message")
    submitted = st.form_submit_button("é€ä¿¡")

if submitted:
    if user_message.strip():
        if "conversation_turns" not in st.session_state or not isinstance(st.session_state["conversation_turns"], list):
            st.session_state["conversation_turns"] = []
        user_text = user_message
        persona_params = adjust_parameters(user_message)
        if len(st.session_state["conversation_turns"]) == 0:
            answer_text = generate_combined_answer(user_message, persona_params)
        else:
            context = "\n".join([f"ã‚ãªãŸ: {turn['user']}\nå›ç­”: {turn['answer']}" for turn in st.session_state["conversation_turns"]])
            answer_text = continue_combined_answer(user_message, context)
        st.session_state["conversation_turns"].append({"user": user_text, "answer": answer_text})
        conversation_container.markdown("### ä¼šè©±å±¥æ­´")
        display_conversation_turns(st.session_state["conversation_turns"])
    else:
        st.warning("ç™ºè¨€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
