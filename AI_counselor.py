import streamlit as st
import requests
import re
from streamlit_chat import message  # pip install streamlit-chat

# ------------------------
# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
# ------------------------
st.set_page_config(page_title="å½¹å ´ãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢ - ãƒãƒ£ãƒƒãƒˆ", layout="wide")

# ------------------------
# ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å…¥åŠ›ï¼ˆç”»é¢ä¸Šéƒ¨ï¼‰
# ------------------------
user_name = st.text_input("ã‚ãªãŸã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value="æ„›åª›çœŒåºè·å“¡", key="user_name")
consult_type = st.radio("ç›¸è«‡ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„", 
                        ("æœ¬äººã®ç›¸è«‡", "ä»–è€…ã®ç›¸è«‡", "ãƒ‡ãƒªã‚±ãƒ¼ãƒˆãªç›¸è«‡"), key="consult_type")

# ------------------------
# å®šæ•°ï¼è¨­å®š
# ------------------------
API_KEY = st.secrets["general"]["api_key"]
MODEL_NAME = "gemini-2.0-flash-001"  # å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´
ROLES = ["ç²¾ç¥ç§‘åŒ»å¸«", "ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼", "ãƒ¡ãƒ³ã‚¿ãƒªã‚¹ãƒˆ", "å†…ç§‘åŒ»"]

# ------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–ï¼ˆä¼šè©±ã‚¿ãƒ¼ãƒ³å˜ä½ã§ç®¡ç†ï¼‰
# ------------------------
if "conversation_turns" not in st.session_state:
    st.session_state["conversation_turns"] = []
if "show_selection_form" not in st.session_state:
    st.session_state["show_selection_form"] = False

# ------------------------
# é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
# ------------------------
if st.button("é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ã‚’é–‹ã"):
    st.session_state["show_selection_form"] = True

if st.session_state.get("show_selection_form", False):
    st.sidebar.header("é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ")
    category = st.sidebar.selectbox("æ‚©ã¿ã®ç¨®é¡", 
                                    ["äººé–“é–¢ä¿‚", "ä»•äº‹", "å®¶åº­", "çµŒæ¸ˆ", "å¥åº·", "ãã®ä»–"], key="category")
    physical_status = st.sidebar.radio("ä½“ã®çŠ¶æ…‹", 
                                       ["è‰¯å¥½", "æ™®é€š", "ä¸èª¿"], key="physical")
    mental_status = st.sidebar.radio("å¿ƒã®çŠ¶æ…‹", 
                                     ["è½ã¡ç€ã„ã¦ã„ã‚‹", "ã‚„ã‚„ä¸å®‰", "ã¨ã¦ã‚‚ä¸å®‰"], key="mental")
    symptom_duration = st.sidebar.selectbox("ç—‡çŠ¶ã®æŒç¶šæœŸé–“", 
                                            ["æ•°æ—¥", "1é€±é–“", "1ãƒ¶æœˆä»¥ä¸Š", "ä¸æ˜"], key="duration")
    stress_level = st.sidebar.slider("ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ« (1-10)", 1, 10, 5, key="stress")
    recent_events = st.sidebar.text_area("æœ€è¿‘ã®å¤§ããªå‡ºæ¥äº‹ï¼ˆä»»æ„ï¼‰", key="events")
    treatment_history = st.sidebar.radio("éå»ã«ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã®æ²»ç™‚çµŒé¨“ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ", 
                                          ["ã¯ã„", "ã„ã„ãˆ"], key="treatment")
    if st.sidebar.button("é¸æŠå†…å®¹ã‚’é€ä¿¡"):
        selection_summary = (
            f"ã€é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ã€‘\n"
            f"æ‚©ã¿ã®ç¨®é¡: {category}\n"
            f"ä½“ã®çŠ¶æ…‹: {physical_status}\n"
            f"å¿ƒã®çŠ¶æ…‹: {mental_status}\n"
            f"ç—‡çŠ¶ã®æŒç¶šæœŸé–“: {symptom_duration}\n"
            f"ã‚¹ãƒˆãƒ¬ã‚¹ãƒ¬ãƒ™ãƒ«: {stress_level}\n"
            f"æœ€è¿‘ã®å‡ºæ¥äº‹: {recent_events}\n"
            f"æ²»ç™‚çµŒé¨“: {treatment_history}"
        )
        if "conversation_turns" not in st.session_state or not isinstance(st.session_state["conversation_turns"], list):
            st.session_state["conversation_turns"] = []
        st.session_state["conversation_turns"].append({"user": selection_summary, "answer": "é¸æŠå¼ç›¸è«‡ãƒ•ã‚©ãƒ¼ãƒ ã®å†…å®¹ãŒé€ä¿¡ã•ã‚Œã¾ã—ãŸã€‚"})
        st.sidebar.success("é€ä¿¡ã—ã¾ã—ãŸï¼")

# ------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ï¼ˆãƒãƒ£ãƒƒãƒˆç”Ÿæˆãƒ»è¡¨ç¤ºï¼‰
# ------------------------
def truncate_text(text, max_length=400):
    return text if len(text) <= max_length else text[:max_length] + "â€¦"

def split_message(message: str, chunk_size=200) -> list:
    return [message[i:i+chunk_size] for i in range(0, len(message), chunk_size)]

def remove_json_artifacts(text: str) -> str:
    if not isinstance(text, str):
        text = str(text) if text else ""
    pattern = r"'parts': \[\{'text':.*?\}\], 'role': 'model'"
    cleaned = re.sub(pattern, "", text, flags=re.DOTALL)
    return cleaned.strip()

def call_gemini_api(prompt: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={API_KEY}"
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(url, json=payload, headers=headers)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡æ™‚ã«ä¾‹å¤–ãŒç™ºç”Ÿã—ã¾ã—ãŸ -> {str(e)}"
    if response.status_code != 200:
        return f"ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status_code} -> {response.text}"
    try:
        rjson = response.json()
        candidates = rjson.get("candidates", [])
        if not candidates:
            return "å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        candidate0 = candidates[0]
        content_val = candidate0.get("content", "")
        if isinstance(content_val, dict):
            parts = content_val.get("parts", [])
            content_str = " ".join([p.get("text", "") for p in parts])
        else:
            content_str = str(content_val)
        content_str = content_str.strip()
        if not content_str:
            return "å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        return remove_json_artifacts(content_str)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã«å¤±æ•—ã—ã¾ã—ãŸ -> {str(e)}"

def adjust_parameters(question: str) -> dict:
    params = {}
    params["ç²¾ç¥ç§‘åŒ»å¸«"] = {"style": "å°‚é–€çš„", "detail": "ç²¾ç¥ç§‘ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚’åŸºã«çš„ç¢ºãªåˆ¤æ–­ã‚’ä¸‹ã™"}
    params["ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼"] = {"style": "å…±æ„Ÿçš„", "detail": "å¯„ã‚Šæ·»ã„ãªãŒã‚‰å„ªã—ãã‚µãƒãƒ¼ãƒˆã™ã‚‹"}
    params["ãƒ¡ãƒ³ã‚¿ãƒªã‚¹ãƒˆ"] = {"style": "æ´å¯ŸåŠ›ã«å¯Œã‚“ã ", "detail": "å¤šè§’çš„ãªå¿ƒç†å­¦çš„è¦–ç‚¹ã‹ã‚‰åˆ†æã™ã‚‹"}
    params["å†…ç§‘åŒ»"] = {"style": "å®Ÿç›´ãª", "detail": "èº«ä½“é¢ã®ä¸èª¿ã‚„ä»–ã®ç—…æ°—ã‚’æ…é‡ã«ãƒã‚§ãƒƒã‚¯ã™ã‚‹"}
    return params

def generate_combined_answer(question: str, persona_params: dict) -> str:
    current_user = st.session_state.get("user_name", "ãƒ¦ãƒ¼ã‚¶ãƒ¼")
    consult_type = st.session_state.get("consult_type", "æœ¬äººã®ç›¸è«‡")
    if consult_type == "ãƒ‡ãƒªã‚±ãƒ¼ãƒˆãªç›¸è«‡":
        consult_info = ("ã“ã®ç›¸è«‡ã¯å¤§äººã®ç™ºé”éšœå®³ï¼ˆä¾‹ï¼šADHDãªã©ï¼‰ã‚’å«ã‚€ã€ãƒ‡ãƒªã‚±ãƒ¼ãƒˆãªç›¸è«‡ã§ã™ã€‚"
                        "ä¿¡é ¼ã§ãã‚‹å…¬çš„æ©Ÿé–¢ã‚„å­¦è¡“è«–æ–‡ã‚’å‚ç…§ã—ã€æ­£ç¢ºãªæƒ…å ±ã«åŸºã¥ã„ãŸå›ç­”ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
    elif consult_type == "ä»–è€…ã®ç›¸è«‡":
        consult_info = "ã“ã®ç›¸è«‡ã¯ã€ä»–è€…ãŒæŠ±ãˆã‚‹éšœå®³ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚å°‚é–€çš„ãªè¦–ç‚¹ã‹ã‚‰å®¢è¦³çš„ãªåˆ¤æ–­ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
    else:
        consult_info = "ã“ã®ç›¸è«‡ã¯æœ¬äººãŒæŠ±ãˆã‚‹æ‚©ã¿ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚"
        
    prompt = f"ã€{current_user}ã•ã‚“ã®è³ªå•ã€‘\n{question}\n\n{consult_info}\n"
    prompt += (
        "ä»¥ä¸‹ã¯ã€4äººã®å°‚é–€å®¶ã®æ„è¦‹ã‚’å†…éƒ¨ã§çµ±åˆã—ãŸçµæœã§ã™ã€‚"
        "å†…éƒ¨ã®è­°è«–å†…å®¹ã¯ä¼ã›ã€ã‚ãªãŸã«å¯¾ã™ã‚‹ä¸€å¯¾ä¸€ã®è‡ªç„¶ãªä¼šè©±ã¨ã—ã¦ã€"
        "ãŸã¨ãˆã°ã€Œã©ã†ã—ãŸã®ï¼Ÿã‚‚ã†å°‘ã—è©³ã—ãæ•™ãˆã¦ã€ã¨ã„ã£ãŸè¿”ç­”ã‚’å«ã‚€å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        "å›ç­”ã¯300ï½400æ–‡å­—ç¨‹åº¦ã§ã€è‡ªç„¶ãªæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    return truncate_text(call_gemini_api(prompt), 400)

def continue_combined_answer(additional_input: str, current_turns: str) -> str:
    prompt = (
        "ã“ã‚Œã¾ã§ã®ä¼šè©±ã®æµã‚Œ:\n" + current_turns + "\n\n" +
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¿½åŠ ç™ºè¨€: " + additional_input + "\n\n" +
        "ä¸Šè¨˜ã®æµã‚Œã‚’è¸ã¾ãˆã€ã•ã‚‰ã«è‡ªç„¶ãªä¼šè©±ã¨ã—ã¦ã€"
        "ãŸã¨ãˆã°ã€Œãã‚Œã§ã©ã†ãªã£ãŸã®ï¼Ÿã€ã¨ã„ã£ãŸè¿”ç­”ã‚’å«ã‚€å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        "å›ç­”ã¯300ï½400æ–‡å­—ç¨‹åº¦ã§ã€è‡ªç„¶ãªæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    return truncate_text(call_gemini_api(prompt), 400)

def generate_summary(discussion: str) -> str:
    prompt = (
        "ä»¥ä¸‹ã¯4äººã®çµ±åˆã•ã‚ŒãŸä¼šè©±å†…å®¹ã§ã™:\n" + discussion + "\n\n" +
        "ã“ã®å†…å®¹ã‚’è¸ã¾ãˆã¦ã€æ„›åª›çœŒåºè·å“¡å‘ã‘ã®ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã«é–¢ã™ã‚‹ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ã€"
        "åˆ†ã‹ã‚Šã‚„ã™ã„ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
    )
    return call_gemini_api(prompt)

def display_chat_bubble(sender: str, message: str, align: str):
    if align == "right":
        bubble_html = f"""
        <div style="
            background-color: #DCF8C6;
            border: 1px solid #ddd;
            border-radius: 10px;
            padding: 8px;
            margin: 5px 0;
            color: #000;
            font-family: Arial, sans-serif;
            text-align: right;
            margin-left: auto;
            max-width: 70%;
        ">
            <strong>{sender}</strong>: {message} ğŸ˜Š
        </div>
        """
    else:
        bubble_html = f"""
        <div style="
            background-color: #FFFACD;
            border: 1px solid #ddd;
            border-radius: 10px;
            padding: 8px;
            margin: 5px 0;
            color: #000;
            font-family: Arial, sans-serif;
            text-align: left;
            max-width: 70%;
        ">
            <strong>{sender}</strong>: {message} ğŸ‘
        </div>
        """
    st.markdown(bubble_html, unsafe_allow_html=True)

def display_conversation_turns(turns: list):
    # æœ€æ–°ã®ä¼šè©±ã‚¿ãƒ¼ãƒ³ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«é€†é †ã§è¡¨ç¤º
    for turn in reversed(turns):
        display_chat_bubble("ã‚ãªãŸ", turn["user"], "right")
        answer_chunks = split_message(turn["answer"], 200)
        for i, chunk in enumerate(answer_chunks):
            suffix = " ğŸ‘‰" if i < len(answer_chunks) - 1 else ""
            display_chat_bubble("å›ç­”", chunk + suffix, "left")

# ------------------------
# Streamlit ã‚¢ãƒ—ãƒªæœ¬ä½“
# ------------------------
st.title("å½¹å ´ãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢ - ãƒãƒ£ãƒƒãƒˆã‚µãƒãƒ¼ãƒˆ")

# --- ä¸Šéƒ¨ï¼šä¼šè©±å±¥æ­´è¡¨ç¤ºã‚¨ãƒªã‚¢ ---
st.header("ä¼šè©±å±¥æ­´")
conversation_container = st.empty()

# --- ä¸Šéƒ¨ï¼šã¾ã¨ã‚å›ç­”ãƒœã‚¿ãƒ³ ---
if st.button("ä¼šè©±ã‚’ã¾ã¨ã‚ã‚‹"):
    if st.session_state.get("conversation_turns", []):
        all_turns = "\n".join([f"ã‚ãªãŸ: {turn['user']}\nå›ç­”: {turn['answer']}" for turn in st.session_state["conversation_turns"]])
        summary = generate_summary(all_turns)
        st.session_state["summary"] = summary
        st.markdown("### ã¾ã¨ã‚å›ç­”\n" + "**ã¾ã¨ã‚:**\n" + summary)
    else:
        st.warning("ã¾ãšã¯ä¼šè©±ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")

# --- ä¸‹éƒ¨ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚¨ãƒªã‚¢ ---
st.header("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›")
with st.form("chat_form", clear_on_submit=True):
    user_message = st.text_area("æ–°ãŸãªç™ºè¨€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ã“ã“ã«å…¥åŠ›", height=100, key="user_message")
    submitted = st.form_submit_button("é€ä¿¡")

if submitted:
    if user_message.strip():
        if "conversation_turns" not in st.session_state or not isinstance(st.session_state["conversation_turns"], list):
            st.session_state["conversation_turns"] = []
        user_text = user_message
        persona_params = adjust_parameters(user_message)
        if len(st.session_state["conversation_turns"]) == 0:
            answer_text = generate_combined_answer(user_message, persona_params)
        else:
            context = "\n".join([f"ã‚ãªãŸ: {turn['user']}\nå›ç­”: {turn['answer']}" for turn in st.session_state["conversation_turns"]])
            answer_text = continue_combined_answer(user_message, context)
        st.session_state["conversation_turns"].append({"user": user_text, "answer": answer_text})
        conversation_container.markdown("### ä¼šè©±å±¥æ­´")
        display_conversation_turns(st.session_state["conversation_turns"])
    else:
        st.warning("ç™ºè¨€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
